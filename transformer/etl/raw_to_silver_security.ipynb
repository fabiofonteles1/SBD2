{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL da camada Raw para camada Silver - Microsoft Security Incident Prediction\n",
    "\n",
    "Este notebook realiza o técnico ETL (Extract, Transform, Load) dos dados da camada Raw para a camada Silver. \n",
    "Ele processa o dataset Microsoft Security Incident Prediction, realizando transformações, limpeza de dados e salvando os dados processados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXTRACT\n",
    "\n",
    "Nesta seção, extraímos os dados do arquivo CSV da camada Raw.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset carregado com sucesso!\n",
      "Dimensões do dataset: (9516837, 45)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>OrgId</th>\n",
       "      <th>IncidentId</th>\n",
       "      <th>AlertId</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>DetectorId</th>\n",
       "      <th>AlertTitle</th>\n",
       "      <th>Category</th>\n",
       "      <th>MitreTechniques</th>\n",
       "      <th>IncidentGrade</th>\n",
       "      <th>...</th>\n",
       "      <th>ResourceType</th>\n",
       "      <th>Roles</th>\n",
       "      <th>OSFamily</th>\n",
       "      <th>OSVersion</th>\n",
       "      <th>AntispamDirection</th>\n",
       "      <th>SuspicionLevel</th>\n",
       "      <th>LastVerdict</th>\n",
       "      <th>CountryCode</th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>180388628218</td>\n",
       "      <td>0</td>\n",
       "      <td>612</td>\n",
       "      <td>123247</td>\n",
       "      <td>2024-06-04T06:05:15.000Z</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>InitialAccess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TruePositive</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>455266534868</td>\n",
       "      <td>88</td>\n",
       "      <td>326</td>\n",
       "      <td>210035</td>\n",
       "      <td>2024-06-14T03:01:25.000Z</td>\n",
       "      <td>58</td>\n",
       "      <td>43</td>\n",
       "      <td>Exfiltration</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FalsePositive</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>242</td>\n",
       "      <td>1445</td>\n",
       "      <td>10630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1056561957389</td>\n",
       "      <td>809</td>\n",
       "      <td>58352</td>\n",
       "      <td>712507</td>\n",
       "      <td>2024-06-13T04:52:55.000Z</td>\n",
       "      <td>423</td>\n",
       "      <td>298</td>\n",
       "      <td>InitialAccess</td>\n",
       "      <td>T1189</td>\n",
       "      <td>FalsePositive</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Suspicious</td>\n",
       "      <td>Suspicious</td>\n",
       "      <td>242</td>\n",
       "      <td>1445</td>\n",
       "      <td>10630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1279900258736</td>\n",
       "      <td>92</td>\n",
       "      <td>32992</td>\n",
       "      <td>774301</td>\n",
       "      <td>2024-06-10T16:39:36.000Z</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>CommandAndControl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BenignPositive</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Suspicious</td>\n",
       "      <td>Suspicious</td>\n",
       "      <td>242</td>\n",
       "      <td>1445</td>\n",
       "      <td>10630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>214748368522</td>\n",
       "      <td>148</td>\n",
       "      <td>4359</td>\n",
       "      <td>188041</td>\n",
       "      <td>2024-06-15T01:08:07.000Z</td>\n",
       "      <td>9</td>\n",
       "      <td>74</td>\n",
       "      <td>Execution</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TruePositive</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>242</td>\n",
       "      <td>1445</td>\n",
       "      <td>10630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Id  OrgId  IncidentId  AlertId                 Timestamp  \\\n",
       "0   180388628218      0         612   123247  2024-06-04T06:05:15.000Z   \n",
       "1   455266534868     88         326   210035  2024-06-14T03:01:25.000Z   \n",
       "2  1056561957389    809       58352   712507  2024-06-13T04:52:55.000Z   \n",
       "3  1279900258736     92       32992   774301  2024-06-10T16:39:36.000Z   \n",
       "4   214748368522    148        4359   188041  2024-06-15T01:08:07.000Z   \n",
       "\n",
       "   DetectorId  AlertTitle           Category MitreTechniques   IncidentGrade  \\\n",
       "0           7           6      InitialAccess             NaN    TruePositive   \n",
       "1          58          43       Exfiltration             NaN   FalsePositive   \n",
       "2         423         298      InitialAccess           T1189   FalsePositive   \n",
       "3           2           2  CommandAndControl             NaN  BenignPositive   \n",
       "4           9          74          Execution             NaN    TruePositive   \n",
       "\n",
       "   ... ResourceType Roles OSFamily OSVersion  AntispamDirection  \\\n",
       "0  ...          NaN   NaN        5        66                NaN   \n",
       "1  ...          NaN   NaN        5        66                NaN   \n",
       "2  ...          NaN   NaN        5        66                NaN   \n",
       "3  ...          NaN   NaN        5        66                NaN   \n",
       "4  ...          NaN   NaN        5        66                NaN   \n",
       "\n",
       "   SuspicionLevel  LastVerdict  CountryCode  State   City  \n",
       "0             NaN          NaN           31      6      3  \n",
       "1             NaN          NaN          242   1445  10630  \n",
       "2      Suspicious   Suspicious          242   1445  10630  \n",
       "3      Suspicious   Suspicious          242   1445  10630  \n",
       "4             NaN          NaN          242   1445  10630  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuração do caminho dos dados\n",
    "data_layer_filepath = '../../'\n",
    "\n",
    "# Carregamento do dataset\n",
    "df = pd.read_csv(data_layer_filepath + 'raw/train.csv', low_memory=False)\n",
    "print(\"Dataset carregado com sucesso!\")\n",
    "print(f\"Dimensões do dataset: {df.shape}\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRANSFORM\n",
    "\n",
    "Nesta seção, realizamos as transformações necessárias nos dados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padronização dos Nomes das Colunas\n",
    "\n",
    "Padronizamos os nomes das colunas para facilitar o processamento. O padrão será: **todos os caracteres em minúsculo, separando palavras com `_`**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeiras 20 colunas padronizadas:\n",
      " 1. id\n",
      " 2. orgid\n",
      " 3. incidentid\n",
      " 4. alertid\n",
      " 5. timestamp\n",
      " 6. detectorid\n",
      " 7. alerttitle\n",
      " 8. category\n",
      " 9. mitretechniques\n",
      "10. incidentgrade\n",
      "11. actiongrouped\n",
      "12. actiongranular\n",
      "13. entitytype\n",
      "14. evidencerole\n",
      "15. deviceid\n",
      "16. sha256\n",
      "17. ipaddress\n",
      "18. url\n",
      "19. accountsid\n",
      "20. accountupn\n",
      "\n",
      "... e mais 25 colunas\n"
     ]
    }
   ],
   "source": [
    "# Backup dos nomes originais\n",
    "original_columns = df.columns.tolist()\n",
    "\n",
    "# Padronização dos nomes das colunas\n",
    "df.columns = [col.lower().replace(' ', '_') for col in df.columns]\n",
    "\n",
    "print(\"Primeiras 20 colunas padronizadas:\")\n",
    "for i, col in enumerate(df.columns[:20]):\n",
    "    print(f\"{i+1:2d}. {col}\")\n",
    "\n",
    "if len(df.columns) > 20:\n",
    "    print(f\"\\n... e mais {len(df.columns) - 20} colunas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise de Valores Ausentes\n",
    "\n",
    "Vamos analisar a presença de valores ausentes no dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 colunas com mais valores nulos:\n",
      "           Coluna  Valores_Nulos  Percentual_Nulos\n",
      "     resourcetype        9509762         99.925658\n",
      "    actiongrouped        9460773         99.410897\n",
      "   actiongranular        9460773         99.410897\n",
      "     threatfamily        9441956         99.213173\n",
      "   emailclusterid        9420025         98.982729\n",
      "antispamdirection        9339535         98.136965\n",
      "            roles        9298686         97.707736\n",
      "   suspicionlevel        8072708         84.825536\n",
      "      lastverdict        7282572         76.523030\n",
      "  mitretechniques        5468386         57.460120\n",
      "    incidentgrade          51340          0.539465\n",
      "        timestamp              0          0.000000\n",
      "               id              0          0.000000\n",
      "       entitytype              0          0.000000\n",
      "       detectorid              0          0.000000\n",
      "       alerttitle              0          0.000000\n",
      "         category              0          0.000000\n",
      "            orgid              0          0.000000\n",
      "       incidentid              0          0.000000\n",
      "          alertid              0          0.000000\n",
      "\n",
      "Colunas com mais de 50% de valores ausentes: 10\n",
      "Primeiras 10: ['resourcetype', 'actiongrouped', 'actiongranular', 'threatfamily', 'emailclusterid', 'antispamdirection', 'roles', 'suspicionlevel', 'lastverdict', 'mitretechniques']\n"
     ]
    }
   ],
   "source": [
    "# Análise de valores nulos\n",
    "null_counts = df.isnull().sum()\n",
    "null_percentages = (null_counts / len(df)) * 100\n",
    "\n",
    "# Criar DataFrame com informações de nulos\n",
    "null_info = pd.DataFrame({\n",
    "    'Coluna': null_counts.index,\n",
    "    'Valores_Nulos': null_counts.values,\n",
    "    'Percentual_Nulos': null_percentages.values\n",
    "})\n",
    "\n",
    "# Ordenar por percentual de nulos\n",
    "null_info = null_info.sort_values('Percentual_Nulos', ascending=False)\n",
    "\n",
    "print(\"Top 20 colunas com mais valores nulos:\")\n",
    "print(null_info.head(20).to_string(index=False))\n",
    "\n",
    "# Identificar colunas com muitos valores ausentes (>50%)\n",
    "high_missing_cols = null_info[null_info['Percentual_Nulos'] > 50]['Coluna'].tolist()\n",
    "print(f\"\\nColunas com mais de 50% de valores ausentes: {len(high_missing_cols)}\")\n",
    "if high_missing_cols:\n",
    "    print(\"Primeiras 10:\", high_missing_cols[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remoção de Colunas com Muitos Valores Ausentes\n",
    "\n",
    "Removemos colunas que têm mais de 80% de valores ausentes, pois não agregam valor significativo ao modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas a serem removidas (>80% ausentes): 8\n",
      "Primeiras 10 colunas a serem removidas:\n",
      "  1. resourcetype\n",
      "  2. actiongrouped\n",
      "  3. actiongranular\n",
      "  4. threatfamily\n",
      "  5. emailclusterid\n",
      "  6. antispamdirection\n",
      "  7. roles\n",
      "  8. suspicionlevel\n",
      "\n",
      "Dimensões após remoção: (9516837, 37)\n",
      "Colunas removidas: 8\n"
     ]
    }
   ],
   "source": [
    "# Definir threshold para remoção (80% de valores ausentes)\n",
    "missing_threshold = 80\n",
    "\n",
    "# Identificar colunas para remoção\n",
    "cols_to_drop = null_info[null_info['Percentual_Nulos'] > missing_threshold]['Coluna'].tolist()\n",
    "\n",
    "print(f\"Colunas a serem removidas (>{missing_threshold}% ausentes): {len(cols_to_drop)}\")\n",
    "if cols_to_drop:\n",
    "    print(\"Primeiras 10 colunas a serem removidas:\")\n",
    "    for i, col in enumerate(cols_to_drop[:10]):\n",
    "        print(f\"  {i+1}. {col}\")\n",
    "\n",
    "# Remover colunas com muitos valores ausentes\n",
    "df_cleaned = df.drop(columns=cols_to_drop)\n",
    "print(f\"\\nDimensões após remoção: {df_cleaned.shape}\")\n",
    "print(f\"Colunas removidas: {df.shape[1] - df_cleaned.shape[1]}\")\n",
    "\n",
    "# Atualizar DataFrame principal\n",
    "df = df_cleaned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise da Variável Target\n",
    "\n",
    "Vamos analisar a variável target `HasDetections` para entender o balanceamento das classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variável 'hasdetections' não encontrada no dataset.\n",
      "Verificando colunas que podem ser a target:\n",
      "['detectorid']\n"
     ]
    }
   ],
   "source": [
    "# Análise da variável target\n",
    "if 'hasdetections' in df.columns:\n",
    "    target_counts = df['hasdetections'].value_counts()\n",
    "    target_percentages = df['hasdetections'].value_counts(normalize=True) * 100\n",
    "    \n",
    "    print(\"Distribuição da variável target (HasDetections):\")\n",
    "    print(f\"\\nContagem:\")\n",
    "    for value, count in target_counts.items():\n",
    "        print(f\"  {value}: {count:,} ({target_percentages[value]:.2f}%)\")\n",
    "    \n",
    "    # Verificar balanceamento\n",
    "    balance_ratio = min(target_counts) / max(target_counts)\n",
    "    print(f\"\\nRazão de balanceamento: {balance_ratio:.3f}\")\n",
    "    if balance_ratio < 0.1:\n",
    "        print(\"⚠️  Dataset altamente desbalanceado!\")\n",
    "    elif balance_ratio < 0.3:\n",
    "        print(\"⚠️  Dataset moderadamente desbalanceado\")\n",
    "    else:\n",
    "        print(\"✅ Dataset relativamente balanceado\")\n",
    "        \n",
    "    # Verificar valores ausentes na target\n",
    "    target_missing = df['hasdetections'].isnull().sum()\n",
    "    print(f\"\\nValores ausentes na variável target: {target_missing}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Variável 'hasdetections' não encontrada no dataset.\")\n",
    "    print(\"Verificando colunas que podem ser a target:\")\n",
    "    potential_targets = [col for col in df.columns if 'detect' in col.lower() or 'target' in col.lower() or 'label' in col.lower()]\n",
    "    if potential_targets:\n",
    "        print(potential_targets)\n",
    "    else:\n",
    "        print(\"Nenhuma coluna target óbvia encontrada.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding de Variáveis Categóricas\n",
    "\n",
    "Vamos aplicar Label Encoding para variáveis categóricas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas categóricas identificadas: 7\n",
      "timestamp: 760944 valores únicos\n",
      "category: 20 valores únicos\n",
      "mitretechniques: 1193 valores únicos\n",
      "incidentgrade: 3 valores únicos\n",
      "entitytype: 33 valores únicos\n",
      "evidencerole: 2 valores únicos\n",
      "lastverdict: 5 valores únicos\n",
      "\n",
      "Encoding aplicado em 7 colunas categóricas.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Identificar colunas categóricas\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remover a variável target se ela for categórica\n",
    "if 'hasdetections' in categorical_cols:\n",
    "    categorical_cols.remove('hasdetections')\n",
    "\n",
    "print(f\"Colunas categóricas identificadas: {len(categorical_cols)}\")\n",
    "\n",
    "# Aplicar Label Encoding para colunas categóricas\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        # Verificar número de categorias únicas\n",
    "        unique_values = df[col].nunique()\n",
    "        print(f\"{col}: {unique_values} valores únicos\")\n",
    "        \n",
    "        # Aplicar Label Encoding\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "print(f\"\\nEncoding aplicado em {len(label_encoders)} colunas categóricas.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento de Valores Ausentes\n",
    "\n",
    "Vamos tratar os valores ausentes restantes usando estratégias apropriadas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores ausentes após encoding:\n",
      "Nenhum valor ausente encontrado!\n",
      "\n",
      "Total de valores ausentes após tratamento: 0\n"
     ]
    }
   ],
   "source": [
    "# Verificar valores ausentes após encoding\n",
    "missing_after_encoding = df.isnull().sum()\n",
    "cols_with_missing = missing_after_encoding[missing_after_encoding > 0]\n",
    "\n",
    "print(\"Valores ausentes após encoding:\")\n",
    "if len(cols_with_missing) > 0:\n",
    "    print(cols_with_missing.sort_values(ascending=False))\n",
    "    \n",
    "    # Estratégias de tratamento\n",
    "    for col in cols_with_missing.index:\n",
    "        if df[col].dtype in ['int64', 'float64']:\n",
    "            # Para colunas numéricas: imputação com mediana\n",
    "            median_value = df[col].median()\n",
    "            df[col].fillna(median_value, inplace=True)\n",
    "            print(f\"  {col}: Preenchido com mediana ({median_value})\")\n",
    "        else:\n",
    "            # Para colunas categóricas: imputação com moda\n",
    "            mode_value = df[col].mode()[0] if len(df[col].mode()) > 0 else 'Unknown'\n",
    "            df[col].fillna(mode_value, inplace=True)\n",
    "            print(f\"  {col}: Preenchido com moda ({mode_value})\")\n",
    "else:\n",
    "    print(\"Nenhum valor ausente encontrado!\")\n",
    "\n",
    "# Verificação final\n",
    "final_missing = df.isnull().sum().sum()\n",
    "print(f\"\\nTotal de valores ausentes após tratamento: {final_missing}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD\n",
    "\n",
    "Nesta seção, carregamos os dados processados para a camada Silver.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando os Dados Processados em CSV\n",
    "\n",
    "Vamos salvar os dados processados na camada Silver.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset da camada Silver salvo com sucesso!\n",
      "Arquivo: ../../silver/security_incident_prediction_silver.csv\n",
      "Dimensões: (9516837, 37)\n",
      "Tamanho do arquivo: 1715.69 MB\n"
     ]
    }
   ],
   "source": [
    "# Criar diretório silver se não existir\n",
    "import os\n",
    "silver_dir = data_layer_filepath + 'silver/'\n",
    "if not os.path.exists(silver_dir):\n",
    "    os.makedirs(silver_dir)\n",
    "    print(f\"Diretório criado: {silver_dir}\")\n",
    "\n",
    "# Salvar dados processados\n",
    "output_file = silver_dir + 'security_incident_prediction_silver.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Dataset da camada Silver salvo com sucesso!\")\n",
    "print(f\"Arquivo: {output_file}\")\n",
    "print(f\"Dimensões: {df.shape}\")\n",
    "print(f\"Tamanho do arquivo: {os.path.getsize(output_file) / 1024**2:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificação Final da Qualidade dos Dados\n",
    "\n",
    "Vamos fazer uma verificação final da qualidade dos dados processados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VERIFICAÇÃO FINAL DA QUALIDADE DOS DADOS ===\n",
      "Dimensões finais do dataset: (9516837, 37)\n",
      "Memória utilizada: 2686.49 MB\n",
      "Total de valores ausentes: 0\n",
      "\n",
      "Tipos de dados finais:\n",
      "int64    37\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Valores infinitos encontrados: 0\n",
      "\n",
      "✅ Verificação de qualidade concluída!\n"
     ]
    }
   ],
   "source": [
    "# Verificação final da qualidade dos dados\n",
    "print(\"=== VERIFICAÇÃO FINAL DA QUALIDADE DOS DADOS ===\")\n",
    "print(f\"Dimensões finais do dataset: {df.shape}\")\n",
    "print(f\"Memória utilizada: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# Verificar valores ausentes\n",
    "missing_final = df.isnull().sum().sum()\n",
    "print(f\"Total de valores ausentes: {missing_final}\")\n",
    "\n",
    "# Verificar tipos de dados\n",
    "print(f\"\\nTipos de dados finais:\")\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "# Verificar variável target\n",
    "if 'hasdetections' in df.columns:\n",
    "    target_dist = df['hasdetections'].value_counts(normalize=True) * 100\n",
    "    print(f\"\\nDistribuição da variável target:\")\n",
    "    print(target_dist)\n",
    "\n",
    "# Verificar se há valores infinitos\n",
    "inf_count = np.isinf(df.select_dtypes(include=[np.number])).sum().sum()\n",
    "print(f\"\\nValores infinitos encontrados: {inf_count}\")\n",
    "\n",
    "print(\"\\n✅ Verificação de qualidade concluída!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
